{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "\n",
    "def parseDataFromURL(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse255/data/beer/beer_50000.json\"\n",
    "data = list(parseData(\"data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "\n",
    "### Convince ourselves that basic linear algebra operations yield the same answer ###\n",
    "\n",
    "X = numpy.matrix(X)\n",
    "y = numpy.matrix(y)\n",
    "numpy.linalg.inv(X.T * X) * X.T * y.T\n",
    "\n",
    "### Do older people rate beer more highly? ###\n",
    "\n",
    "data2 = [d for d in data if 'user/ageInSeconds' in d]\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  #feat.append(datum['user/ageInSeconds'])\n",
    "  feat.append(datum['beer/ABV'])\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data2]\n",
    "y = [d['review/overall'] for d in data2]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "\n",
    "### How much do women prefer beer over men? ###\n",
    "\n",
    "data2 = [d for d in data if 'user/gender' in d]\n",
    "\n",
    "def feature(datum):\n",
    "  feat = [1]\n",
    "  if datum['user/gender'] == \"Male\":\n",
    "    feat.append(0)\n",
    "  else:\n",
    "    feat.append(1)\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data2]\n",
    "y = [d['review/overall'] for d in data2]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n",
    "\n",
    "### Gradient descent ###\n",
    "\n",
    "# Objective\n",
    "def f(theta, X, y, lam):\n",
    "  theta = numpy.matrix(theta).T\n",
    "  X = numpy.matrix(X)\n",
    "  y = numpy.matrix(y).T\n",
    "  diff = X*theta - y\n",
    "  diffSq = diff.T*diff\n",
    "  diffSqReg = diffSq / len(X) + lam*(theta.T*theta)\n",
    "  print(\"offset =\", diffSqReg.flatten().tolist())\n",
    "  return diffSqReg.flatten().tolist()[0]\n",
    "\n",
    "# Derivative\n",
    "def fprime(theta, X, y, lam):\n",
    "  theta = numpy.matrix(theta).T\n",
    "  X = numpy.matrix(X)\n",
    "  y = numpy.matrix(y).T\n",
    "  diff = X*theta - y\n",
    "  res = 2*X.T*diff / len(X) + 2*lam*theta\n",
    "  print(\"gradient =\", numpy.array(res.flatten().tolist()[0]))\n",
    "  return numpy.array(res.flatten().tolist()[0])\n",
    "\n",
    "scipy.optimize.fmin_l_bfgs_b(f, [0,0], fprime, args = (X, y, 0.1))\n",
    "\n",
    "### Random features ###\n",
    "\n",
    "def feature(datum):\n",
    "  return [random.random() for x in range(30)]\n",
    "\n",
    "X = [feature(d) for d in data2]\n",
    "y = [d['review/overall'] for d in data2]\n",
    "theta,residuals,rank,s = numpy.linalg.lstsq(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "def parseDataFromURL(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse258/data/amazon/book_descriptions_50000.json\n",
    "data = list(parseData(\"data/amazon/book_descriptions_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "### Naive bayes to determine p(childrens book | mentions wizards and mentions witches) ###\n",
    "\n",
    "# p(childrens book)\n",
    "prior = [\"Children's Books\" in b['categories'] for b in data]\n",
    "prior = sum(prior) * 1.0 / len(prior)\n",
    "\n",
    "# p(isn't children's book)\n",
    "prior_neg = 1 - prior\n",
    "\n",
    "# p(mentions wizards | is childrens)\n",
    "p1 = ['wizard' in b['description'] for b in data if \"Children's Books\" in b['categories']]\n",
    "p1 = sum(p1) * 1.0 / len(p1)\n",
    "\n",
    "# p(mentions wizards | isn't childrens)\n",
    "p1_neg = ['wizard' in b['description'] for b in data if not (\"Children's Books\" in b['categories'])]\n",
    "p1_neg = sum(p1_neg) * 1.0 / len(p1_neg)\n",
    "\n",
    "# p(mentions witches | is childrens)\n",
    "p2 = ['witch' in b['description'] for b in data if \"Children's Books\" in b['categories']]\n",
    "p2 = sum(p2) * 1.0 / len(p2)\n",
    "\n",
    "# p(mentions witches | isn't childrens)\n",
    "p2_neg = ['witch' in b['description'] for b in data if not (\"Children's Books\" in b['categories'])]\n",
    "p2_neg = sum(p2_neg) * 1.0 / len(p2_neg)\n",
    "\n",
    "# Prediction\n",
    "\n",
    "score = prior * p1 * p2\n",
    "score_neg = prior_neg * p1_neg * p2_neg\n",
    "\n",
    "# Actual ('non-naive') probability\n",
    "\n",
    "p = [\"Children's Books\" in b['categories'] for b in data if 'witch' in b['description'] and 'wizard' in b['description']]\n",
    "p = sum(p) * 1.0 / len(p)\n",
    "\n",
    "### Logistic Regression -- \"Judging a book by its cover\"\n",
    "\n",
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse255/data/amazon/book_images_5000.json\n",
    "data = list(parseData(\"data/amazon/book_images_5000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "X = [b['image_feature'] for b in data]\n",
    "y = [\"Children's Books\" in b['categories'] for b in data]\n",
    "\n",
    "X_train = X[:2500]\n",
    "y_train = y[:2500]\n",
    "\n",
    "X_test = X[2500:]\n",
    "y_test = y[2500:]\n",
    "\n",
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "# clf = svm.SVC(C=1000, kernel='linear')\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# train_predictions = clf.predict(X_train)\n",
    "# test_predictions = clf.predict(X_test)\n",
    "\n",
    "# Logistic regression classifier\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = mod.predict(X_train)\n",
    "test_predictions = mod.predict(X_test)\n",
    "\n",
    "\n",
    "### Diagnostics\n",
    "\n",
    "# From https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data\n",
    "f = open(\"5year.arff\", 'r')\n",
    "\n",
    "# Reading in data\n",
    "while not '@data' in f.readline():\n",
    "    pass\n",
    "\n",
    "dataset = []\n",
    "for l in f:\n",
    "    if '?' in l: # Missing entry\n",
    "        continue\n",
    "    l = l.split(',')\n",
    "    values = [1] + [float(x) for x in l]\n",
    "    values[-1] = values[-1] > 0 # Convert to bool\n",
    "    dataset.append(values)\n",
    "\n",
    "# Data setup\n",
    "X = [d[:-1] for d in dataset]\n",
    "y = [d[-1] for d in dataset]\n",
    "\n",
    "# Fit model\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "\n",
    "# How many positive predictions?\n",
    "sum(pred)\n",
    "\n",
    "# Balanced model\n",
    "mod = linear_model.LogisticRegression(C=1.0, class_weight='balanced')\n",
    "mod.fit(X,y)\n",
    "\n",
    "pred = mod.predict(X)\n",
    "\n",
    "# How many positive predictions?\n",
    "sum(pred)\n",
    "\n",
    "# Train/validation/test splits\n",
    "\n",
    "# Shuffle the data\n",
    "Xy = list(zip(X,y))\n",
    "random.shuffle(Xy)\n",
    "\n",
    "X = [d[0] for d in Xy]\n",
    "y = [d[1] for d in Xy]\n",
    "\n",
    "N = len(y)\n",
    "\n",
    "Ntrain = 1000\n",
    "Nvalid = 1000\n",
    "Ntest = 1031\n",
    "\n",
    "Xtrain = X[:Ntrain]\n",
    "Xvalid = X[Ntrain:Ntrain+Nvalid]\n",
    "Xtest = X[Ntrain+Nvalid:]\n",
    "\n",
    "ytrain = y[:Ntrain]\n",
    "yvalid = y[Ntrain:Ntrain+Nvalid]\n",
    "ytest = y[Ntrain+Nvalid:]\n",
    "\n",
    "mod.fit(Xtrain, ytrain)\n",
    "\n",
    "pred = mod.predict(Xtest)\n",
    "\n",
    "correct = pred == ytest\n",
    "\n",
    "# True positives, false positives, etc.\n",
    "\n",
    "TP_ = numpy.logical_and(pred, ytest)\n",
    "FP_ = numpy.logical_and(pred, numpy.logical_not(ytest))\n",
    "TN_ = numpy.logical_and(numpy.logical_not(pred), numpy.logical_not(ytest))\n",
    "FN_ = numpy.logical_and(numpy.logical_not(pred), ytest)\n",
    "\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "\n",
    "# accuracy\n",
    "sum(correct) / len(correct)\n",
    "(TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "# BER\n",
    "1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "\n",
    "# Ranking\n",
    "\n",
    "scores = mod.decision_function(Xtest)\n",
    "\n",
    "scores_labels = list(zip(scores, ytest))\n",
    "scores_labels.sort(reverse = True)\n",
    "\n",
    "sortedlabels = [x[1] for x in scores_labels]\n",
    "\n",
    "# precision / recall\n",
    "retrieved = sum(pred)\n",
    "relevant = sum(ytest)\n",
    "intersection = sum([y and p for y,p in zip(ytest,pred)])\n",
    "\n",
    "precision = intersection / retrieved\n",
    "recall = intersection / relevant\n",
    "\n",
    "# precision at 10\n",
    "sum(sortedlabels[:10]) / 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import scipy.optimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_fan = list(parseData(\"fantasy_10000.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_len = [len(d['review_text']) for d in parsed_fan]\n",
    "ratings = [d['rating'] for d in parsed_fan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24d747af248>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(review_len,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 Stars': 326,\n",
       " '1 Stars': 286,\n",
       " '2 Stars': 778,\n",
       " '3 Stars': 2113,\n",
       " '4 Stars': 3265,\n",
       " '5 Stars': 3232}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero = ratings.count(0)\n",
    "one = ratings.count(1)\n",
    "two = ratings.count(2)\n",
    "three = ratings.count(3)\n",
    "four = ratings.count(4)\n",
    "five = ratings.count(5)\n",
    "plt.bar([0,1,2,3,4,5],[zero,one,two,three,four,five])\n",
    "{'0 Stars':zero,'1 Stars':one,'2 Stars':two,'3 Stars':three,'4 Stars':four,'5 Stars':five}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27830.232344719698"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((review_len-np.mean(review_len)*(ratings-np.mean(ratings)))/((review_len-np.mean(review_len))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Theta 0': 3.685681355016952,\n",
       " 'Theta 1': 6.873716748962768e-05,\n",
       " 'Mean Squared Error': 15522.08662235535}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter = LinearRegression().fit(np.array(review_len).reshape(-1, 1), np.array(ratings).reshape(-1, 1)).intercept_\n",
    "coef = LinearRegression().fit(np.array(review_len).reshape(-1, 1), np.array(ratings).reshape(-1, 1)).coef_\n",
    "pred = inter + ([coef[0][0]*x for x in review_len])\n",
    "mse = np.mean(sum((ratings - pred)**2))\n",
    "{'Theta 0': inter[0], 'Theta 1': coef[0][0], 'Mean Squared Error': mse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "# Briefly  explain  why  the coefficient θ1 in this model is different from the one in Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Theta 0': 3.689167374290135,\n",
       " 'Theta 1': [7.584074903973375e-05, -0.03279289354454786],\n",
       " 'Mean Squared Error': 15498.351692774624}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = [d['n_comments'] for d in parsed_fan]\n",
    "inter2D = LinearRegression().fit(np.array([review_len,comments]).T, np.array(ratings).reshape(-1, 1)).intercept_\n",
    "coef2D = LinearRegression().fit(np.array([review_len,comments]).T, np.array(ratings).reshape(-1, 1)).coef_\n",
    "pred2D = inter2D + ([coef2D[0][0]*x for x in review_len]) + ([coef2D[0][1]*x for x in comments])\n",
    "mse2D = np.mean(sum((ratings - pred2D)**2))\n",
    "{'Theta 0': inter2D[0], 'Theta 1': [coef2D[0][0],coef2D[0][1]], 'Mean Squared Error': mse2D}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_review = [x/max(review_len) for x in review_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "firDeMo = LinearRegression().fit(np.array(divided_review).reshape(-1, 1), np.array(ratings).reshape(-1, 1))\n",
    "seDeMo = LinearRegression().fit(np.array([divided_review,divided_review]).T, np.array(ratings).reshape(-1, 1))\n",
    "thDeMo = LinearRegression().fit(np.array([divided_review,divided_review,divided_review]).T, np.array(ratings).reshape(-1, 1))\n",
    "foDeMo = LinearRegression().fit(np.array([divided_review,divided_review,divided_review,divided_review]).T, np.array(ratings).reshape(-1, 1))\n",
    "fiDeMo = LinearRegression().fit(np.array([divided_review,divided_review,divided_review,divided_review,divided_review]).T, np.array(ratings).reshape(-1, 1))\n",
    "\n",
    "firDeIn = firDeMo.intercept_\n",
    "seDeIn = seDeMo.intercept_\n",
    "thDeIn = thDeMo.intercept_\n",
    "foDeIn = foDeMo.intercept_\n",
    "fiDeIn = fiDeMo.intercept_\n",
    "\n",
    "firDeCo = firDeMo.coef_\n",
    "seDeCo = seDeMo.coef_\n",
    "thDeCo = thDeMo.coef_\n",
    "foDeCo = foDeMo.coef_\n",
    "fiDeCo = fiDeMo.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predFir = firDeIn + ([firDeCo[0][0]*x for x in divided_review])\n",
    "predSe = seDeIn + ([seDeCo[0][0]*x for x in divided_review]) + ([seDeCo[0][1]*x for x in divided_review])\n",
    "predTh = thDeIn + ([thDeCo[0][0]*x for x in divided_review]) + ([thDeCo[0][1]*x for x in divided_review]) + ([thDeCo[0][2]*x for x in divided_review])\n",
    "predFo = foDeIn + ([foDeCo[0][0]*x for x in divided_review]) + ([foDeCo[0][1]*x for x in divided_review]) + ([foDeCo[0][2]*x for x in divided_review]) + ([foDeCo[0][3]*x for x in divided_review])\n",
    "predFi = fiDeIn + ([fiDeCo[0][0]*x for x in divided_review]) + ([fiDeCo[0][1]*x for x in divided_review]) + ([fiDeCo[0][2]*x for x in divided_review]) + ([fiDeCo[0][3]*x for x in divided_review]) + ([fiDeCo[0][4]*x for x in divided_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseFir = np.mean(sum((ratings - predFir)**2))\n",
    "mseSe = np.mean(sum((ratings - predSe)**2))\n",
    "mseTh = np.mean(sum((ratings - predTh)**2))\n",
    "mseFo = np.mean(sum((ratings - predFo)**2))\n",
    "mseFi = np.mean(sum((ratings - predFi)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE Degree 1': 15522.08662235535,\n",
       " 'MSE Degree 2': 15522.086622355346,\n",
       " 'MSE Degree 3': 15522.086622355346,\n",
       " 'MSE Degree 4': 15522.086622355348,\n",
       " 'MSE Degree 5': 15522.086622355342}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'MSE Degree 1':mseFir,'MSE Degree 2':mseSe,'MSE Degree 3':mseTh,'MSE Degree 4':mseFo,'MSE Degree 5':mseFi}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "# Train Model With Training Split And Find MSE For Both Training And Test Split Using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value = divided_review\n",
    "y_value = ratings\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_value, y_value, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "firDeTr = LinearRegression().fit(np.array(x_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1))\n",
    "seDeTr = LinearRegression().fit(np.array([x_train,x_train]).T, np.array(y_train).reshape(-1, 1))\n",
    "thDeTr = LinearRegression().fit(np.array([x_train,x_train,x_train]).T, np.array(y_train).reshape(-1, 1))\n",
    "foDeTr = LinearRegression().fit(np.array([x_train,x_train,x_train,x_train]).T, np.array(y_train).reshape(-1, 1))\n",
    "fiDeTr = LinearRegression().fit(np.array([x_train,x_train,x_train,x_train,x_train]).T, np.array(y_train).reshape(-1, 1))\n",
    "\n",
    "firIn = firDeTr.intercept_\n",
    "seIn = seDeTr.intercept_\n",
    "thIn = thDeTr.intercept_\n",
    "foIn = foDeTr.intercept_\n",
    "fiIn = fiDeTr.intercept_\n",
    "\n",
    "firCo = firDeTr.coef_\n",
    "seCo = seDeTr.coef_\n",
    "thCo = thDeTr.coef_\n",
    "foCo = foDeTr.coef_\n",
    "fiCo = fiDeTr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_beer = list(parseData(\"beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_gender = [d for d in parsed_beer if 'user/gender' in d.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_len = [len(d['review/text']) for d in with_gender]\n",
    "genders = [d['user/gender'] for d in with_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(np.array(beer_len).reshape(-1,1), np.array(genders).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf_bal = LogisticRegression(class_weight='balanced').fit(np.array(beer_len).reshape(-1,1), np.array(genders).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
