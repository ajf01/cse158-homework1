{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import scipy.optimize\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in open(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parses the fantasy json file\n",
    "parsed_fan = list(parseData(\"fantasy_10000.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieves the review length and ratings from the parsed text\n",
    "review_len = [len(d['review_text']) for d in parsed_fan]\n",
    "ratings = [d['rating'] for d in parsed_fan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x206e01be508>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots the review length against ratings as a scatter\n",
    "plt.scatter(review_len,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 Stars': 326,\n",
       " '1 Stars': 286,\n",
       " '2 Stars': 778,\n",
       " '3 Stars': 2113,\n",
       " '4 Stars': 3265,\n",
       " '5 Stars': 3232}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Counts the amount of each star rating\n",
    "zero = ratings.count(0)\n",
    "one = ratings.count(1)\n",
    "two = ratings.count(2)\n",
    "three = ratings.count(3)\n",
    "four = ratings.count(4)\n",
    "five = ratings.count(5)\n",
    "\n",
    "#Plots the amount of star ratings against their respective counts\n",
    "plt.bar([0,1,2,3,4,5],[zero,one,two,three,four,five])\n",
    "plt.xlabel('Stars')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Star Distribution')\n",
    "{'0 Stars':zero,'1 Stars':one,'2 Stars':two,'3 Stars':three,'4 Stars':four,'5 Stars':five}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Theta 0': 3.685681355016952,\n",
       " 'Theta 1': 6.873716748962768e-05,\n",
       " 'Mean Squared Error': 1.5522086622355349}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses sklearn to train a Linear Regression Model to obtain the intercept and coefficient values\n",
    "inter = LinearRegression().fit(np.array(review_len).reshape(-1, 1), np.array(ratings).reshape(-1, 1)).intercept_\n",
    "coef = LinearRegression().fit(np.array(review_len).reshape(-1, 1), np.array(ratings).reshape(-1, 1)).coef_\n",
    "\n",
    "#Uses the intercept and coefficient values to create predictions and calculate the mean squared error\n",
    "pred = inter + ([coef[0][0]*x for x in review_len])\n",
    "mse = (sum((ratings - pred)**2))/len(pred)\n",
    "{'Theta 0': inter[0], 'Theta 1': coef[0][0], 'Mean Squared Error': mse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Theta 0': 3.689167374290135,\n",
       " 'Theta 1': 7.584074903973375e-05,\n",
       " 'Theta 2': -0.03279289354454786,\n",
       " 'Mean Squared Error': 1.5498351692774623}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses sklearn to train a Linear Regression Model to obtain the intercept and coefficient values\n",
    "comments = [d['n_comments'] for d in parsed_fan]\n",
    "inter2D = LinearRegression().fit(np.array([review_len,comments]).T, np.array(ratings).reshape(-1, 1)).intercept_\n",
    "coef2D = LinearRegression().fit(np.array([review_len,comments]).T, np.array(ratings).reshape(-1, 1)).coef_\n",
    "\n",
    "#Uses the intercept and coefficient values to create predictions and calculate the mean squared error\n",
    "pred2D = inter2D + ([coef2D[0][0]*x for x in review_len]) + ([coef2D[0][1]*x for x in comments])\n",
    "mse2D = (sum((ratings - pred2D)**2))/len(pred2D)\n",
    "{'Theta 0': inter2D[0], 'Theta 1': coef2D[0][0],'Theta 2': coef2D[0][1], 'Mean Squared Error': mse2D}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient for Theta 1 in this model is different than the coefficient for Theta 1 in question 2, because this model has a second feature variable. This second feature variable gives the model a better understanding of how to predict ratings, and as such adjusted the coefficient of Theta 1 to a better value in order to reduce the Mean Squared Error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescales review length feature by dividing every value by the largest review length\n",
    "divided_review = [x/max(review_len) for x in review_len]\n",
    "divided_review2 = [x**2 for x in divided_review]\n",
    "divided_review3 = [x**3 for x in divided_review]\n",
    "divided_review4 = [x**4 for x in divided_review]\n",
    "divided_review5 = [x**5 for x in divided_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses sklearn to train a 5 different Linear Regression Models of different degrees\n",
    "firDeMo = LinearRegression().fit(np.array(divided_review).reshape(-1, 1), np.array(ratings).reshape(-1, 1))\n",
    "seDeMo = LinearRegression().fit(np.array([divided_review,divided_review2]).T, np.array(ratings).reshape(-1, 1))\n",
    "thDeMo = LinearRegression().fit(np.array([divided_review,divided_review2,divided_review3]).T, np.array(ratings).reshape(-1, 1))\n",
    "foDeMo = LinearRegression().fit(np.array([divided_review,divided_review2,divided_review3,divided_review4]).T, np.array(ratings).reshape(-1, 1))\n",
    "fiDeMo = LinearRegression().fit(np.array([divided_review,divided_review2,divided_review3,divided_review4,divided_review5]).T, np.array(ratings).reshape(-1, 1))\n",
    "\n",
    "#Uses the trained Linear Regression Models to obtain the intercepts\n",
    "firDeIn = firDeMo.intercept_\n",
    "seDeIn = seDeMo.intercept_\n",
    "thDeIn = thDeMo.intercept_\n",
    "foDeIn = foDeMo.intercept_\n",
    "fiDeIn = fiDeMo.intercept_\n",
    "\n",
    "#Uses the trained Linear Regression Models to obtain the coefficients\n",
    "firDeCo = firDeMo.coef_\n",
    "seDeCo = seDeMo.coef_\n",
    "thDeCo = thDeMo.coef_\n",
    "foDeCo = foDeMo.coef_\n",
    "fiDeCo = fiDeMo.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the intercept and coefficient values of all the models to create predictions\n",
    "predFir = firDeIn + ([firDeCo[0][0]*x for x in divided_review])\n",
    "predSe = seDeIn + ([seDeCo[0][0]*x for x in divided_review]) + ([seDeCo[0][1]*x for x in divided_review2])\n",
    "predTh = thDeIn + ([thDeCo[0][0]*x for x in divided_review]) + ([thDeCo[0][1]*x for x in divided_review2]) + ([thDeCo[0][2]*x for x in divided_review3])\n",
    "predFo = foDeIn + ([foDeCo[0][0]*x for x in divided_review]) + ([foDeCo[0][1]*x for x in divided_review2]) + ([foDeCo[0][2]*x for x in divided_review3]) + ([foDeCo[0][3]*x for x in divided_review4])\n",
    "predFi = fiDeIn + ([fiDeCo[0][0]*x for x in divided_review]) + ([fiDeCo[0][1]*x for x in divided_review2]) + ([fiDeCo[0][2]*x for x in divided_review3]) + ([fiDeCo[0][3]*x for x in divided_review4]) + ([fiDeCo[0][4]*x for x in divided_review5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the predictions from all models to calculate the mean squared error\n",
    "mseFir = (sum((ratings - predFir)**2))/len(predFir)\n",
    "mseSe = (sum((ratings - predSe)**2))/len(predSe)\n",
    "mseTh = (sum((ratings - predTh)**2))/len(predTh)\n",
    "mseFo = (sum((ratings - predFo)**2))/len(predFo)\n",
    "mseFi = (sum((ratings - predFi)**2))/len(predFi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE Degree 1': 1.5522086622355349,\n",
       " 'MSE Degree 2': 1.5506567696339435,\n",
       " 'MSE Degree 3': 1.5497985323805485,\n",
       " 'MSE Degree 4': 1.5496291324524716,\n",
       " 'MSE Degree 5': 1.5496142023298654}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'MSE Degree 1':mseFir,'MSE Degree 2':mseSe,'MSE Degree 3':mseTh,'MSE Degree 4':mseFo,'MSE Degree 5':mseFi}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the rescaled review length data randomly in half\n",
    "x_train, x_test, y_train, y_test = train_test_split(divided_review, ratings, test_size=0.5)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(divided_review2, ratings, test_size=0.5)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(divided_review3, ratings, test_size=0.5)\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(divided_review4, ratings, test_size=0.5)\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(divided_review5, ratings, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses sklearn to train a 5 different Linear Regression Models of different degrees using the training set\n",
    "firDeTr = LinearRegression().fit(np.array(x_train).reshape(-1, 1), np.array(y_train).reshape(-1, 1))\n",
    "seDeTr = LinearRegression().fit(np.array([x_train,x_train2]).T, np.array(y_train2).reshape(-1, 1))\n",
    "thDeTr = LinearRegression().fit(np.array([x_train,x_train2,x_train3]).T, np.array(y_train3).reshape(-1, 1))\n",
    "foDeTr = LinearRegression().fit(np.array([x_train,x_train2,x_train3,x_train4]).T, np.array(y_train4).reshape(-1, 1))\n",
    "fiDeTr = LinearRegression().fit(np.array([x_train,x_train2,x_train3,x_train4,x_train5]).T, np.array(y_train5).reshape(-1, 1))\n",
    "\n",
    "#Uses the trained Linear Regression Models to obtain the intercept\n",
    "firIn = firDeTr.intercept_\n",
    "seIn = seDeTr.intercept_\n",
    "thIn = thDeTr.intercept_\n",
    "foIn = foDeTr.intercept_\n",
    "fiIn = fiDeTr.intercept_\n",
    "\n",
    "#Uses the trained Linear Regression Models to obtain the coefficients\n",
    "firCo = firDeTr.coef_\n",
    "seCo = seDeTr.coef_\n",
    "thCo = thDeTr.coef_\n",
    "foCo = foDeTr.coef_\n",
    "fiCo = fiDeTr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the intercept and coefficient values to create predictions for the training set\n",
    "predFirTr = firIn + ([firCo[0][0]*x for x in x_train])\n",
    "predSeTr = seIn + ([seCo[0][0]*x for x in x_train]) + ([seCo[0][1]*x for x in x_train2])\n",
    "predThTr = thIn + ([thCo[0][0]*x for x in x_train]) + ([thCo[0][1]*x for x in x_train2]) + ([thCo[0][2]*x for x in x_train3])\n",
    "predFoTr = foIn + ([foCo[0][0]*x for x in x_train]) + ([foCo[0][1]*x for x in x_train2]) + ([foCo[0][2]*x for x in x_train3]) + ([foCo[0][3]*x for x in x_train4])\n",
    "predFiTr = fiIn + ([fiCo[0][0]*x for x in x_train]) + ([fiCo[0][1]*x for x in x_train2]) + ([fiCo[0][2]*x for x in x_train3]) + ([fiCo[0][3]*x for x in x_train4]) + ([fiCo[0][4]*x for x in x_train5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the training predictions to calculate the mean squared error for the training set\n",
    "mseFirTr = (sum((y_train - predFirTr)**2))/len(predFirTr)\n",
    "mseSeTr = (sum((y_train2 - predSeTr)**2))/len(predSeTr)\n",
    "mseThTr = (sum((y_train3 - predThTr)**2))/len(predThTr)\n",
    "mseFoTr = (sum((y_train4 - predFoTr)**2))/len(predFoTr)\n",
    "mseFiTr = (sum((y_train5 - predFiTr)**2))/len(predFiTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the intercept and coefficient values to create predictions for the test set\n",
    "predFirTe = firIn + ([firCo[0][0]*x for x in x_test])\n",
    "predSeTe = seIn + ([seCo[0][0]*x for x in x_test]) + ([seCo[0][1]*x for x in x_test2])\n",
    "predThTe = thIn + ([thCo[0][0]*x for x in x_test]) + ([thCo[0][1]*x for x in x_test2]) + ([thCo[0][2]*x for x in x_test3])\n",
    "predFoTe = foIn + ([foCo[0][0]*x for x in x_test]) + ([foCo[0][1]*x for x in x_test2]) + ([foCo[0][2]*x for x in x_test3]) + ([foCo[0][3]*x for x in x_test4])\n",
    "predFiTe = fiIn + ([fiCo[0][0]*x for x in x_test]) + ([fiCo[0][1]*x for x in x_test2]) + ([fiCo[0][2]*x for x in x_test3]) + ([fiCo[0][3]*x for x in x_test4]) + ([fiCo[0][4]*x for x in x_test5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses the test predictions to calculate the mean squared error for the test set\n",
    "mseFirTe = (sum((y_test - predFirTe)**2))/len(predFirTe)\n",
    "mseSeTe = (sum((y_test2 - predSeTe)**2))/len(predSeTe)\n",
    "mseThTe = (sum((y_test3 - predThTe)**2))/len(predThTe)\n",
    "mseFoTe = (sum((y_test4 - predFoTe)**2))/len(predFoTe)\n",
    "mseFiTe = (sum((y_test5 - predFiTe)**2))/len(predFiTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE Train Degree 1': 1.5702140380107583,\n",
       " 'MSE Train Degree 2': 1.5413548976854232,\n",
       " 'MSE Train Degree 3': 1.5354764783374562,\n",
       " 'MSE Train Degree 4': 1.559401208110402,\n",
       " 'MSE Train Degree 5': 1.5772604520589921}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'MSE Train Degree 1':mseFirTr,'MSE Train Degree 2':mseSeTr,'MSE Train Degree 3':mseThTr,\\\n",
    "       'MSE Train Degree 4':mseFoTr,'MSE Train Degree 5':mseFiTr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE Test Degree 1': 1.534597784842971,\n",
       " 'MSE Test Degree 2': 1.5711500890936245,\n",
       " 'MSE Test Degree 3': 1.5805766100838834,\n",
       " 'MSE Test Degree 4': 1.5558378839936766,\n",
       " 'MSE Test Degree 5': 1.5334510048416972}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'MSE Test Degree 1':mseFirTe,'MSE Test Degree 2':mseSeTe,'MSE Test Degree 3':mseThTe,\\\n",
    "       'MSE Test Degree 4':mseFoTe,'MSE Test Degree 5':mseFiTe}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parses the beer data\n",
    "parsed_beer = list(parseData(\"beer_50000.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeps only data where user specifies gender\n",
    "with_gender = [d for d in parsed_beer if 'user/gender' in d.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieves the beer review length data and the gender data\n",
    "beer_len = [len(d['review/text']) for d in with_gender]\n",
    "#genders = [d['user/gender'] for d in with_gender]\n",
    "genders = [1 if d['user/gender'] == 'Female' else 0 for d in with_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Trains a logistic regression model with beer review length to predict gender\n",
    "clf = LogisticRegression().fit(np.array(beer_len).reshape(-1,1), np.array(genders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for the gender given beer review lengths\n",
    "pred_LR = clf.predict(np.array(beer_len).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_ = np.logical_and(pred_LR, genders)\n",
    "FP_ = np.logical_and(pred_LR, np.logical_not(genders))\n",
    "TN_ = np.logical_and(np.logical_not(pred_LR), np.logical_not(genders))\n",
    "FN_ = np.logical_and(np.logical_not(pred_LR), genders)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TP = sum(TP_)\n",
    "FP = sum(FP_)\n",
    "TN = sum(TN_)\n",
    "FN = sum(FN_)\n",
    "\n",
    "#Converts To Rates\n",
    "TPR = TP/(TP+FN)\n",
    "FPR = FP/(FP+TN)\n",
    "TNR = TN/(TN+FP)\n",
    "FNR = FN/(FN+TP)\n",
    "\n",
    "# accuracy\n",
    "#sum(correct) / len(correct)\n",
    "#(TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "#Calculates Balanced Error Rate\n",
    "ber = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positive': 0.0,\n",
       " 'False Positive': 0.0,\n",
       " 'True Negative': 1.0,\n",
       " 'False Negative': 1.0,\n",
       " 'BER': 0.5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'True Positive':TPR,'False Positive':FPR,'True Negative':TNR,'False Negative':FNR,'BER':ber}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Trains a balanced logistic regression model with beer review length to predict gender\n",
    "clf_bal = LogisticRegression(class_weight='balanced').fit(np.array(beer_len).reshape(-1,1), np.array(genders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for the gender given beer review lengths\n",
    "pred_LRB = clf_bal.predict(np.array(beer_len).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_bal = np.logical_and(pred_LRB, genders)\n",
    "FP_bal = np.logical_and(pred_LRB, np.logical_not(genders))\n",
    "TN_bal = np.logical_and(np.logical_not(pred_LRB), np.logical_not(genders))\n",
    "FN_bal = np.logical_and(np.logical_not(pred_LRB), genders)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TP_B = sum(TP_bal)\n",
    "FP_B = sum(FP_bal)\n",
    "TN_B = sum(TN_bal)\n",
    "FN_B = sum(FN_bal)\n",
    "\n",
    "#Converts To Rates\n",
    "TPR_B = TP_B/(TP_B+FN_B)\n",
    "FPR_B = FP_B/(FP_B+TN_B)\n",
    "TNR_B = TN_B/(TN_B+FP_B)\n",
    "FNR_B = FN_B/(FN_B+TP_B)\n",
    "\n",
    "# accuracy\n",
    "#sum(correct) / len(correct)\n",
    "#(TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "#Calculates Balanced Error Rate\n",
    "ber_bal = 1 - 0.5 * (TP_B / (TP_B + FN_B) + TN_B / (TN_B + FP_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positive': 0.6461038961038961,\n",
       " 'False Positive': 0.5795969146553869,\n",
       " 'True Negative': 0.42040308534461307,\n",
       " 'False Negative': 0.3538961038961039,\n",
       " 'BER': 0.46674650927574546}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'True Positive':TPR_B,'False Positive':FPR_B,'True Negative':TNR_B,'False Negative':FNR_B,'BER':ber_bal}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested a variety of different features to be included in the improved model to lower BER, but the most successful combination I found was using beer/brewerID, review/overall, user/profileName, beer/ABV, and review/taste. I decided on these features because of how I thought female or male gendered drinkers would react to them. I thought since the data was so heavily biased towards male reviewers perhaps they would leave higher reviews and overall and for taste. This might be because they are more experienced with beers and are able to appreciate it more. They might also choose certain beers based on brand or alcohol content that inexperienced drinkers would not know to do by. I also expected that there would be slight deviations between male and female usernames. This thought process is what steered me towards these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created lists for the different features that would be used in this improved logistic regression model\n",
    "brewID = [int(d['beer/brewerId']) for d in with_gender]\n",
    "reviewO = [d['review/overall'] for d in with_gender]\n",
    "profile = [len(d['user/profileName']) for d in with_gender]\n",
    "#beerStyle = [len(d['beer/style']) for d in with_gender]\n",
    "#aroma = [d['review/aroma'] for d in with_gender]\n",
    "abv = [d['beer/ABV'] for d in with_gender]\n",
    "taste = [d['review/taste'] for d in with_gender]\n",
    "#palate = [d['review/palate'] for d in with_gender]\n",
    "#appear = [d['review/appearance'] for d in with_gender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afong\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Trains a balanced logistic regression model to predict gender\n",
    "improved_clf = LogisticRegression(class_weight='balanced')\\\n",
    "               .fit(np.array([beer_len,brewID,reviewO,profile,abv,taste]).T, np.array(genders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for the gender\n",
    "impPred = improved_clf.predict(np.array([beer_len,brewID,reviewO,profile,abv,taste]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the True Positive, False Positive, True Negative, and False Negative array values\n",
    "TP_imp = np.logical_and(impPred, genders)\n",
    "FP_imp = np.logical_and(impPred, np.logical_not(genders))\n",
    "TN_imp = np.logical_and(np.logical_not(impPred), np.logical_not(genders))\n",
    "FN_imp = np.logical_and(np.logical_not(impPred), genders)\n",
    "\n",
    "#Finds the number of True Positive, False Positive, True Negative, and False Negative\n",
    "TP_I = sum(TP_imp)\n",
    "FP_I = sum(FP_imp)\n",
    "TN_I = sum(TN_imp)\n",
    "FN_I = sum(FN_imp)\n",
    "\n",
    "#Converts To Rates\n",
    "TPR_I = TP_I/(TP_I+FN_I)\n",
    "FPR_I = FP_I/(FP_I+TN_I)\n",
    "TNR_I = TN_I/(TN_I+FP_I)\n",
    "FNR_I = FN_I/(FN_I+TP_I)\n",
    "\n",
    "# accuracy\n",
    "#sum(correct) / len(correct)\n",
    "#(TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "#Calculates Balanced Error Rate\n",
    "ber_imp = 1 - 0.5 * (TP_I / (TP_I + FN_I) + TN_I / (TN_I + FP_I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positive': 0.6201298701298701,\n",
       " 'False Positive': 0.4988803184871859,\n",
       " 'True Negative': 0.5011196815128142,\n",
       " 'False Negative': 0.37987012987012986,\n",
       " 'BER': 0.43937522417865793}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'True Positive':TPR_I,'False Positive':FPR_I,'True Negative':TNR_I,'False Negative':FNR_I,'BER':ber_imp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
